{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063b3f13-a3bf-4b3d-872b-21469c392e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import utils.visulaiser as visulaiser\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57cde6b9-e602-4bfd-8144-ca76c5999371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555c4fe",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5547a353-09ec-4c1b-b2ad-7fb4aded5794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 00:36:48.657067: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-12 00:36:48.657134: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-12 00:36:48.659119: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 00:36:48.671017: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b517e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.qwen = base_model.model\n",
    "        self.linear = nn.Linear(896, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.qwen(**inputs)\n",
    "        cls_token = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.linear(cls_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42d910",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464c81f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272f521bcd8f4b6fa1c045e4426be784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b4d0676a6b47aa8fd7c8b9c44d41ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': 72.0}\n"
     ]
    }
   ],
   "source": [
    "# Load GSM8K dataset\n",
    "# dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "dataset = load_from_disk(\"./gsm8k_saved\")\n",
    "\n",
    "def extract_final_answer(answer):\n",
    "    \"\"\"\n",
    "    Extracts only the numerical value after '####' in the answer field.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"####\\s*([\\d\\.]+)\", answer)  # Match number after ####\n",
    "    return float(match.group(1)) if match else 0  # Return extracted number\n",
    "\n",
    "# Process training and test sets\n",
    "for split in [\"train\", \"test\"]:\n",
    "    dataset[split] = dataset[split].map(lambda example: {\n",
    "        \"question\": example[\"question\"],\n",
    "        # \"answer\": tokenizer(extract_final_answer(example[\"answer\"]),\n",
    "        #                     padding='max_length',\n",
    "        #                     truncation=True,\n",
    "        #                     max_length=16,\n",
    "        #                     return_tensors='pt').to(device),\n",
    "        \"answer\": extract_final_answer(example[\"answer\"])\n",
    "    })\n",
    "\n",
    "# Save processed dataset\n",
    "dataset.save_to_disk(\"./gsm8k_cleaned\")\n",
    "\n",
    "# Print an example to verify\n",
    "print(dataset[\"train\"][0])\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d7bced9-cfc5-4e4c-bebe-8b5426d0c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(example):\n",
    "    # print(example)\n",
    "    return f\"Question: YOU ARE A EXPERT AT MATH. NOW ANSWER THIS QUESTION - {example['question']}. REPLY JUST THE FINAL ANSWER AS A NUMBER. Answer: \"\n",
    "\n",
    "# Tokenize data\n",
    "def preprocess_function(examples):\n",
    "    texts = format_example(examples)\n",
    "    tokens = tokenizer(texts, \n",
    "                     padding=\"max_length\", \n",
    "                     truncation=True, \n",
    "                     max_length=128, \n",
    "                     return_tensors=\"pt\")\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "tokenized_train = train_data.map(preprocess_function, batched=False)\n",
    "tokenized_test = test_data.map(preprocess_function, batched=False)\n",
    "\n",
    "# Rename \n",
    "tokenized_train = tokenized_train.remove_columns('question')\n",
    "# tokenized_train = tokenized_train.rename_column('answer', 'labels')\n",
    "\n",
    "tokenized_test = tokenized_test.remove_columns('question')\n",
    "# tokenized_test = tokenized_test.rename_column('answer', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d88b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_train.shuffle(seed=42)#.select(range(1000))\n",
    "small_eval_dataset = tokenized_test.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580addba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=1)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c8a44",
   "metadata": {},
   "source": [
    "# PyTorch Bare Bones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e614e8f-c364-4770-a759-07e03588fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_metric, optimizer, num_epochs):\n",
    "    num_training_steps = num_epochs * len(dataloader)\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    \n",
    "    model = ModifiedModel(base_model)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=5e-3)\n",
    "    loss_metric = nn.MSELoss()\n",
    "    \n",
    "    loss_arr = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        for i, sample in enumerate(dataloader):\n",
    "            batch = {k: torch.tensor(v).to(device) for k, v in sample.items() if k != 'answer'}\n",
    "            \n",
    "            output = model(batch)\n",
    "            if isinstance(output, tuple):  # Ensure proper indexing\n",
    "                output = output[0]\n",
    "            \n",
    "            # Ensure shape consistency for loss calculation\n",
    "            loss = loss_metric(output.view(-1, 1).float(), sample['answer'].view(-1, 1).to(device).float())\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            if (i % 100 == 0):\n",
    "                print(output.item(), sample['answer'].item())\n",
    "                print(f\"Step {i}: Loss = {loss.item()}\")\n",
    "    \n",
    "        loss_arr.append(running_loss / len(train_dataloader))\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    return loss_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba46874f-ff79-477b-82dd-3e73d3b1ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModifiedModel(base_model)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-3)\n",
    "loss_metric = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf871de-b29e-4e80-8d31-92ad32768669",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m(model, train_dataloader, loss_metric, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, loss_metric, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93c20256-70c4-44dc-9ef3-2ad0ed74001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary(device=None, abbreviated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27e643c6-8632-4f50-8881-03ab6bb747e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Reset the peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb61be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), './qwen_gsm8k_finetuned/pytorch_model.bin')\n",
    "tokenizer.save_pretrained(\"./qwen_gsm8k_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cbd69-9122-49ee-a719-1e130d0cd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model again\n",
    "model = ModifiedModel(base_model)  # Recreate your modified model\n",
    "model.load_state_dict(torch.load('./qwen_gsm8k_finetuned/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869a9cf-1239-4a06-ae6f-908e67e4a366",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c195faf-ef79-4525-b6c7-b868306811b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    num_training_steps = len(dataloader)\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    running_loss = 0\n",
    "    nCorrect = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(dataloader):\n",
    "            batch = {k: torch.tensor(v).to(device) for k, v in sample.items() if k != 'answer'}\n",
    "            \n",
    "            output = model(batch)\n",
    "            if isinstance(output, tuple):  # Ensure proper indexing\n",
    "                output = output[0]\n",
    "            \n",
    "            # Ensure shape consistency for loss calculation\n",
    "            loss = loss_metric(output.view(-1, 1).float(), sample['answer'].view(-1, 1).to(device).float())\n",
    "            nCorrect += (output.view(-1, 1).float() == sample['answer'].view(-1, 1).to(device).float()) \n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if (i % 100 == 0):\n",
    "                print(f\"Step {i}: Loss = {loss.item()}\")\n",
    "\n",
    "    return nCorrect / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2876afc5-e2ff-44c5-b7dc-61e4f3fe87de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807a6e3ff95141ac84236b6344f50a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss = 12708.708984375\n",
      "Step 100: Loss = 899.7828979492188\n",
      "Step 200: Loss = 3.757678508758545\n",
      "Step 300: Loss = 47496.15625\n",
      "Step 400: Loss = 247942.71875\n",
      "Step 500: Loss = 288.5423278808594\n",
      "Step 600: Loss = 104895.5078125\n",
      "Step 700: Loss = 625088448.0\n",
      "Step 800: Loss = 128.3656768798828\n",
      "Step 900: Loss = 2277.062744140625\n",
      "Step 1000: Loss = 15.132217407226562\n",
      "Step 1100: Loss = 658.2655029296875\n",
      "Step 1200: Loss = 487.9842834472656\n",
      "Step 1300: Loss = 668.4796142578125\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, eval_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edbd77e0-192a-4d14-8da5-e43b44eab608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: tensor([[0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\" , acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
